{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-20T04:12:12.225892Z","iopub.status.busy":"2024-10-20T04:12:12.22505Z","iopub.status.idle":"2024-10-20T04:12:34.88679Z","shell.execute_reply":"2024-10-20T04:12:34.885644Z","shell.execute_reply.started":"2024-10-20T04:12:12.225833Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","from sklearn.base import clone\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.model_selection import StratifiedKFold\n","from scipy.optimize import minimize\n","from concurrent.futures import ThreadPoolExecutor\n","from tqdm import tqdm\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from keras.models import Model\n","from keras.layers import Input, Dense\n","from keras.optimizers import Adam\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","from colorama import Fore, Style\n","from IPython.display import clear_output\n","import warnings\n","from lightgbm import LGBMRegressor\n","from xgboost import XGBRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.impute import SimpleImputer, KNNImputer\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create output folders\n","output_folder = 'output'\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","# Create separate analysis output folders\n","analysis_output_folder = 'analysis_output'\n","os.makedirs(analysis_output_folder, exist_ok=True)\n","\n","physical_analysis_output_folder = 'analysis_output/physical'\n","os.makedirs(physical_analysis_output_folder, exist_ok=True)\n","\n","fitness_analysis_output_folder = 'analysis_output/fitness'\n","os.makedirs(fitness_analysis_output_folder, exist_ok=True)\n","\n","bia_analysis_output_folder = 'analysis_output/bia'\n","os.makedirs(bia_analysis_output_folder, exist_ok=True)\n","\n","child_info_analysis_output_folder = 'analysis_output/child_info'\n","os.makedirs(child_info_analysis_output_folder, exist_ok=True)\n","\n","actigraphy_analysis_output_folder = 'analysis_output/actigraphy'\n","os.makedirs(actigraphy_analysis_output_folder, exist_ok=True)\n","\n","\n","# Set display all columns in dataframes property\n","pd.options.display.max_columns = None\n","\n","# Supress warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["SEED = 42\n","n_splits = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:12:34.889624Z","iopub.status.busy":"2024-10-20T04:12:34.888832Z","iopub.status.idle":"2024-10-20T04:12:34.89971Z","shell.execute_reply":"2024-10-20T04:12:34.898226Z","shell.execute_reply.started":"2024-10-20T04:12:34.88958Z"},"trusted":true},"outputs":[],"source":["# Load and process data files\n","def process_file(filename, dirname):\n","    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n","    df.drop('step', axis=1, inplace=True)\n","    return df.describe().values.reshape(-1), filename.split('=')[1]\n","\n","# Load time series data\n","def load_time_series(dirname) -> pd.DataFrame:\n","    ids = os.listdir(dirname)\n","    \n","    with ThreadPoolExecutor() as executor:\n","        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n","    \n","    stats, indexes = zip(*results)\n","    \n","    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n","    df['id'] = indexes\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:12:34.902343Z","iopub.status.busy":"2024-10-20T04:12:34.901837Z","iopub.status.idle":"2024-10-20T04:12:34.934431Z","shell.execute_reply":"2024-10-20T04:12:34.933012Z","shell.execute_reply.started":"2024-10-20T04:12:34.902256Z"},"trusted":true},"outputs":[],"source":["# Sparse Autoencoder Model\n","class SparseAutoencoder(nn.Module):\n","    def __init__(self, input_dim, sparsity_weight=1e-5):\n","        super(SparseAutoencoder, self).__init__()\n","        self.sparsity_weight = sparsity_weight\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 16),\n","            nn.ReLU()\n","        )\n","        \n","        self.decoder = nn.Sequential(\n","            nn.Linear(16, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, input_dim),\n","            nn.Sigmoid()  # Outputs in the range [0, 1]\n","        )\n","        \n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return encoded, decoded\n","\n","# Preparing Data\n","# Option to use different scalers: MinMaxScaler, StandardScaler, RobustScaler\n","def prepare_data(data, scaler_type='MinMaxScaler'):\n","    if scaler_type == 'StandardScaler':\n","        scaler = StandardScaler()\n","    elif scaler_type == 'RobustScaler':\n","        scaler = RobustScaler()\n","    else:\n","        scaler = MinMaxScaler()\n","    \n","    data_scaled = scaler.fit_transform(data)\n","    return torch.tensor(data_scaled, dtype=torch.float32), scaler\n","\n","# Apply PCA for Dimensionality Reduction\n","# This can help focus the autoencoder on the most relevant features\n","def apply_pca(data, n_components=0.95):\n","    pca = PCA(n_components=n_components)\n","    data_pca = pca.fit_transform(data)\n","    return data_pca, pca\n","\n","# Early Stopping Functionality\n","def early_stopping(patience):\n","    class EarlyStopping:\n","        def __init__(self, patience=patience):\n","            self.patience = patience\n","            self.counter = 0\n","            self.best_loss = float('inf')\n","            self.early_stop = False\n","        \n","        def __call__(self, loss):\n","            if loss < self.best_loss:\n","                self.best_loss = loss\n","                self.counter = 0\n","            else:\n","                self.counter += 1\n","                if self.counter >= self.patience:\n","                    self.early_stop = True\n","    return EarlyStopping()\n","\n","# Training the Sparse Autoencoder with DataFrame Output\n","def perform_autoencoder(data, epochs=100, batch_size=32, learning_rate=0.001, patience=10, scaler_type='MinMaxScaler', use_pca=False, sparsity_weight=1e-5):\n","    # Preprocess Data\n","    if use_pca:\n","        data, pca = apply_pca(data)\n","\n","    data_tensor, scaler = prepare_data(data, scaler_type=scaler_type)\n","    train_data, val_data = train_test_split(data_tensor, test_size=0.2, random_state=42)\n","\n","    train_loader = DataLoader(TensorDataset(train_data), batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(TensorDataset(val_data), batch_size=batch_size, shuffle=False)\n","\n","    model = SparseAutoencoder(input_dim=data.shape[1], sparsity_weight=sparsity_weight)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    criterion = nn.SmoothL1Loss()  # Changed to Smooth L1 Loss\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    stopper = early_stopping(patience=patience)\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        train_loss = 0.0\n","        for batch in train_loader:\n","            batch = batch[0].to(device)\n","            optimizer.zero_grad()\n","            encoded, outputs = model(batch)\n","            \n","            # Reconstruction loss\n","            loss = criterion(outputs, batch)\n","            \n","            # Sparsity penalty (L1 regularization on encoded activations)\n","            l1_penalty = torch.mean(torch.abs(encoded))\n","            loss += sparsity_weight * l1_penalty\n","            \n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item() * batch.size(0)\n","\n","        train_loss /= len(train_loader.dataset)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for batch in val_loader:\n","                batch = batch[0].to(device)\n","                _, outputs = model(batch)\n","                loss = criterion(outputs, batch)\n","                val_loss += loss.item() * batch.size(0)\n","\n","        val_loss /= len(val_loader.dataset)\n","        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n","\n","        # Early stopping\n","        stopper(val_loss)\n","        if stopper.early_stop:\n","            print(f\"Early stopping at epoch {epoch + 1}\")\n","            break\n","\n","    # Convert tensor back to DataFrame for consistency\n","    _, data_decoded = model(data_tensor.to(device))\n","    data_decoded = data_decoded.cpu().detach().numpy()\n","    df_encoded = pd.DataFrame(data_decoded, columns=[f'feature_{i}' for i in range(data_decoded.shape[1])])\n","    return df_encoded\n","\n","# Usage example\n","# Assuming 'data' is your input dataset as a NumPy array or pandas DataFrame.\n","# df_encoded = train_sparse_autoencoder(data, epochs=100, batch_size=32, learning_rate=0.001, patience=10, scaler_type='StandardScaler', use_pca=True, sparsity_weight=1e-5)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:12:34.938627Z","iopub.status.busy":"2024-10-20T04:12:34.938107Z","iopub.status.idle":"2024-10-20T04:14:23.605568Z","shell.execute_reply":"2024-10-20T04:14:23.604336Z","shell.execute_reply.started":"2024-10-20T04:12:34.938575Z"},"trusted":true},"outputs":[],"source":["def feature_engineering(df):\n","    season_cols = [col for col in df.columns if 'Season' in col]\n","    df = df.drop(season_cols, axis=1) \n","    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n","    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n","    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n","    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n","    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n","    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n","    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n","    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n","    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n","    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n","    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n","    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n","    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n","    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n","    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n","\n","    df['Age_Weight'] = df['Basic_Demos-Age'] * df['Physical-Weight']\n","    df['Sex_BMI'] = df['Basic_Demos-Sex'] * df['Physical-BMI']\n","    df['Sex_HeartRate'] = df['Basic_Demos-Sex'] * df['Physical-HeartRate']\n","    df['Age_WaistCirc'] = df['Basic_Demos-Age'] * df['Physical-Waist_Circumference']\n","    df['BMI_FitnessMaxStage'] = df['Physical-BMI'] * df['Fitness_Endurance-Max_Stage']\n","    df['Weight_GripStrengthDominant'] = df['Physical-Weight'] * df['FGC-FGC_GSD']\n","    df['Weight_GripStrengthNonDominant'] = df['Physical-Weight'] * df['FGC-FGC_GSND']\n","    df['HeartRate_FitnessTime'] = df['Physical-HeartRate'] * (df['Fitness_Endurance-Time_Mins'] + df['Fitness_Endurance-Time_Sec'])\n","    df['Age_PushUp'] = df['Basic_Demos-Age'] * df['FGC-FGC_PU']\n","    df['FFMI_Age'] = df['BIA-BIA_FFMI'] * df['Basic_Demos-Age']\n","    df['InternetUse_SleepDisturbance'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['SDS-SDS_Total_Raw']\n","    df['CGAS_BMI'] = df['CGAS-CGAS_Score'] * df['Physical-BMI']\n","    df['CGAS_FitnessMaxStage'] = df['CGAS-CGAS_Score'] * df['Fitness_Endurance-Max_Stage']\n","    \n","    return df\n","\n","train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n","test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n","sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n","\n","train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n","test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n","\n","df_train = train_ts.drop('id', axis=1)\n","df_test = test_ts.drop('id', axis=1)\n","\n","train_ts_encoded = perform_autoencoder(df_train, epochs=100, batch_size=32, learning_rate=0.001, patience=10, use_pca=False, scaler_type='MinMaxScaler', sparsity_weight=1e-5)\n","test_ts_encoded = perform_autoencoder(df_test, epochs=100, batch_size=32, learning_rate=0.001, patience=10, use_pca=False, scaler_type='MinMaxScaler', sparsity_weight=1e-5)\n","\n","time_series_cols = train_ts_encoded.columns.tolist()\n","train_ts_encoded[\"id\"]=train_ts[\"id\"]\n","test_ts_encoded['id']=test_ts[\"id\"]\n","\n","train = pd.merge(train, train_ts_encoded, how=\"left\", on='id')\n","test = pd.merge(test, test_ts_encoded, how=\"left\", on='id')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:23.607811Z","iopub.status.busy":"2024-10-20T04:14:23.607053Z","iopub.status.idle":"2024-10-20T04:14:23.833571Z","shell.execute_reply":"2024-10-20T04:14:23.832427Z","shell.execute_reply.started":"2024-10-20T04:14:23.607765Z"},"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:23.835387Z","iopub.status.busy":"2024-10-20T04:14:23.83497Z","iopub.status.idle":"2024-10-20T04:14:31.767899Z","shell.execute_reply":"2024-10-20T04:14:31.766668Z","shell.execute_reply.started":"2024-10-20T04:14:23.835335Z"},"trusted":true},"outputs":[],"source":["imputer = KNNImputer(n_neighbors=5)\n","numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns\n","imputed_data = imputer.fit_transform(train[numeric_cols])\n","train_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n","train_imputed['sii'] = train_imputed['sii'].round().astype(int)\n","for col in train.columns:\n","    if col not in numeric_cols:\n","        train_imputed[col] = train[col]\n","        \n","train = train_imputed\n","\n","train = feature_engineering(train)\n","train = train.dropna(thresh=10, axis=0)\n","test = feature_engineering(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:31.770633Z","iopub.status.busy":"2024-10-20T04:14:31.769579Z","iopub.status.idle":"2024-10-20T04:14:32.006577Z","shell.execute_reply":"2024-10-20T04:14:32.005349Z","shell.execute_reply.started":"2024-10-20T04:14:31.770556Z"},"trusted":true},"outputs":[],"source":["train.drop('id', axis=1)\n","train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:32.008726Z","iopub.status.busy":"2024-10-20T04:14:32.008276Z","iopub.status.idle":"2024-10-20T04:14:32.289352Z","shell.execute_reply":"2024-10-20T04:14:32.288331Z","shell.execute_reply.started":"2024-10-20T04:14:32.008684Z"},"trusted":true},"outputs":[],"source":["test.drop('id', axis=1)\n","test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:32.29152Z","iopub.status.busy":"2024-10-20T04:14:32.291053Z","iopub.status.idle":"2024-10-20T04:14:32.314512Z","shell.execute_reply":"2024-10-20T04:14:32.313358Z","shell.execute_reply.started":"2024-10-20T04:14:32.291467Z"},"trusted":true},"outputs":[],"source":["featuresCols = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n","                'CGAS-CGAS_Score', 'Physical-BMI',\n","                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n","                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n","                'Fitness_Endurance-Max_Stage',\n","                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n","                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n","                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n","                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n","                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n","                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n","                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n","                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n","                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n","                'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total',\n","                'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n","                'SDS-SDS_Total_T',\n","                'PreInt_EduHx-computerinternet_hoursday', 'sii', 'BMI_Age','Internet_Hours_Age','BMI_Internet_Hours',\n","                'BFP_BMI', 'FFMI_BFP', 'FMI_BFP', 'LST_TBW', 'BFP_BMR', 'BFP_DEE', 'BMR_Weight', 'DEE_Weight',\n","                'SMM_Height', 'Muscle_to_Fat', 'Hydration_Status', 'ICW_TBW','Age_Weight','Sex_BMI','Sex_HeartRate','Age_WaistCirc','BMI_FitnessMaxStage','Weight_GripStrengthDominant','Weight_GripStrengthNonDominant','HeartRate_FitnessTime',\n","'Age_PushUp','FFMI_Age','InternetUse_SleepDisturbance','CGAS_BMI','CGAS_FitnessMaxStage']\n","\n","featuresCols += time_series_cols\n","\n","train = train[featuresCols]\n","train = train.dropna(subset='sii')\n","\n","featuresCols = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n","                'CGAS-CGAS_Score', 'Physical-BMI',\n","                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n","                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n","                'Fitness_Endurance-Max_Stage',\n","                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n","                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n","                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n","                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n","                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n","                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n","                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n","                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n","                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n","                'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total',\n","                'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n","                'SDS-SDS_Total_T',\n","                'PreInt_EduHx-computerinternet_hoursday', 'BMI_Age','Internet_Hours_Age','BMI_Internet_Hours',\n","                'BFP_BMI', 'FFMI_BFP', 'FMI_BFP', 'LST_TBW', 'BFP_BMR', 'BFP_DEE', 'BMR_Weight', 'DEE_Weight',\n","                'SMM_Height', 'Muscle_to_Fat', 'Hydration_Status', 'ICW_TBW','Age_Weight','Sex_BMI','Sex_HeartRate','Age_WaistCirc','BMI_FitnessMaxStage','Weight_GripStrengthDominant','Weight_GripStrengthNonDominant','HeartRate_FitnessTime',\n","'Age_PushUp','FFMI_Age','InternetUse_SleepDisturbance','CGAS_BMI','CGAS_FitnessMaxStage']\n","\n","featuresCols += time_series_cols\n","test = test[featuresCols]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:32.319779Z","iopub.status.busy":"2024-10-20T04:14:32.319364Z","iopub.status.idle":"2024-10-20T04:14:32.517875Z","shell.execute_reply":"2024-10-20T04:14:32.516592Z","shell.execute_reply.started":"2024-10-20T04:14:32.319736Z"},"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:32.519826Z","iopub.status.busy":"2024-10-20T04:14:32.519363Z","iopub.status.idle":"2024-10-20T04:14:32.798569Z","shell.execute_reply":"2024-10-20T04:14:32.79738Z","shell.execute_reply.started":"2024-10-20T04:14:32.519776Z"},"trusted":true},"outputs":[],"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:32.800698Z","iopub.status.busy":"2024-10-20T04:14:32.800157Z","iopub.status.idle":"2024-10-20T04:14:32.815922Z","shell.execute_reply":"2024-10-20T04:14:32.814675Z","shell.execute_reply.started":"2024-10-20T04:14:32.80064Z"},"trusted":true},"outputs":[],"source":["if np.any(np.isinf(train)):\n","    train = train.replace([np.inf, -np.inf], np.nan)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:32.817914Z","iopub.status.busy":"2024-10-20T04:14:32.817522Z","iopub.status.idle":"2024-10-20T04:14:32.836683Z","shell.execute_reply":"2024-10-20T04:14:32.8354Z","shell.execute_reply.started":"2024-10-20T04:14:32.817875Z"},"trusted":true},"outputs":[],"source":["def quadratic_weighted_kappa(y_true, y_pred):\n","    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n","\n","def threshold_Rounder(oof_non_rounded, thresholds):\n","    return np.where(oof_non_rounded < thresholds[0], 0,\n","                    np.where(oof_non_rounded < thresholds[1], 1,\n","                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n","\n","def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n","    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n","    return -quadratic_weighted_kappa(y_true, rounded_p)\n","\n","def TrainML(model_class, test_data):\n","    X = train.drop(['sii'], axis=1)\n","    y = train['sii']\n","\n","    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n","    \n","    train_S = []\n","    test_S = []\n","    \n","    oof_non_rounded = np.zeros(len(y), dtype=float) \n","    oof_rounded = np.zeros(len(y), dtype=int) \n","    test_preds = np.zeros((len(test_data), n_splits))\n","\n","    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n","        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n","        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n","\n","        model = clone(model_class)\n","        model.fit(X_train, y_train)\n","\n","        y_train_pred = model.predict(X_train)\n","        y_val_pred = model.predict(X_val)\n","\n","        oof_non_rounded[test_idx] = y_val_pred\n","        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n","        oof_rounded[test_idx] = y_val_pred_rounded\n","\n","        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n","        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n","\n","        train_S.append(train_kappa)\n","        test_S.append(val_kappa)\n","        \n","        test_preds[:, fold] = model.predict(test_data)\n","        \n","        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n","        clear_output(wait=True)\n","\n","    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n","    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n","\n","    KappaOPtimizer = minimize(evaluate_predictions,\n","                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n","                              method='Nelder-Mead')\n","    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n","    \n","    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n","    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n","\n","    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n","\n","    tpm = test_preds.mean(axis=1)\n","    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n","    \n","    submission = pd.DataFrame({\n","        'id': sample['id'],\n","        'sii': tpTuned\n","    })\n","\n","    return submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:32.83891Z","iopub.status.busy":"2024-10-20T04:14:32.838438Z","iopub.status.idle":"2024-10-20T04:14:32.857018Z","shell.execute_reply":"2024-10-20T04:14:32.855698Z","shell.execute_reply.started":"2024-10-20T04:14:32.838859Z"},"trusted":true},"outputs":[],"source":["Params = {\n","    'learning_rate': 0.046,\n","    'max_depth': 12,\n","    'num_leaves': 478,\n","    'min_data_in_leaf': 13,\n","    'feature_fraction': 0.893,\n","    'bagging_fraction': 0.784,\n","    'bagging_freq': 4,\n","    'lambda_l1': 10,  # Increased from 6.59\n","    'lambda_l2': 0.01  # Increased from 2.68e-06\n","}\n","\n","\n","XGB_Params = {\n","    'learning_rate': 0.05,\n","    'max_depth': 6,\n","    'n_estimators': 200,\n","    'subsample': 0.8,\n","    'colsample_bytree': 0.8,\n","    'reg_alpha': 1,  # Increased from 0.1\n","    'reg_lambda': 5,  # Increased from 1\n","    'random_state': SEED,\n","    'tree_method': 'exact'\n","}\n","\n","\n","CatBoost_Params = {\n","    'learning_rate': 0.05,\n","    'depth': 6,\n","    'iterations': 200,\n","    'random_seed': SEED,\n","    'verbose': 0,\n","    'l2_leaf_reg': 10  # Increase this value\n","}\n","\n","# Create model instances\n","Light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)\n","XGB_Model = XGBRegressor(**XGB_Params)\n","CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n","\n","# Combine models using Voting Regressor\n","voting_model = VotingRegressor(estimators=[\n","    ('lightgbm', Light),\n","    ('xgboost', XGB_Model),\n","    ('catboost', CatBoost_Model)\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:14:32.858873Z","iopub.status.busy":"2024-10-20T04:14:32.858492Z","iopub.status.idle":"2024-10-20T04:15:42.667115Z","shell.execute_reply":"2024-10-20T04:15:42.665844Z","shell.execute_reply.started":"2024-10-20T04:14:32.858835Z"},"trusted":true},"outputs":[],"source":["Submission1 = TrainML(voting_model, test)\n","\n","# Save submission\n","Submission1.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:15:42.669354Z","iopub.status.busy":"2024-10-20T04:15:42.668834Z","iopub.status.idle":"2024-10-20T04:15:42.682268Z","shell.execute_reply":"2024-10-20T04:15:42.681123Z","shell.execute_reply.started":"2024-10-20T04:15:42.669258Z"},"trusted":true},"outputs":[],"source":["Submission1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:15:42.684744Z","iopub.status.busy":"2024-10-20T04:15:42.684226Z","iopub.status.idle":"2024-10-20T04:18:25.16235Z","shell.execute_reply":"2024-10-20T04:18:25.161144Z","shell.execute_reply.started":"2024-10-20T04:15:42.684692Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n","test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n","sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n","\n","def process_file(filename, dirname):\n","    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n","    df.drop('step', axis=1, inplace=True)\n","    return df.describe().values.reshape(-1), filename.split('=')[1]\n","\n","def load_time_series(dirname) -> pd.DataFrame:\n","    ids = os.listdir(dirname)\n","    \n","    with ThreadPoolExecutor() as executor:\n","        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n","    \n","    stats, indexes = zip(*results)\n","    \n","    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n","    df['id'] = indexes\n","    return df\n","        \n","train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n","test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n","\n","time_series_cols = train_ts.columns.tolist()\n","time_series_cols.remove(\"id\")\n","\n","train = pd.merge(train, train_ts, how=\"left\", on='id')\n","test = pd.merge(test, test_ts, how=\"left\", on='id')\n","\n","train = train.drop('id', axis=1)\n","test = test.drop('id', axis=1)   \n","\n","featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n","                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n","                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n","                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n","                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n","                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n","                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n","                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n","                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n","                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n","                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n","                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n","                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n","                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n","                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n","                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n","                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n","                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n","\n","featuresCols += time_series_cols\n","\n","train = train[featuresCols]\n","train = train.dropna(subset='sii')\n","\n","cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n","          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n","          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n","\n","def update(df):\n","    global cat_c\n","    for c in cat_c: \n","        df[c] = df[c].fillna('Missing')\n","        df[c] = df[c].astype('category')\n","    return df\n","        \n","train = update(train)\n","test = update(test)\n","\n","def create_mapping(column, dataset):\n","    unique_values = dataset[column].unique()\n","    return {value: idx for idx, value in enumerate(unique_values)}\n","\n","for col in cat_c:\n","    mapping = create_mapping(col, train)\n","    mappingTe = create_mapping(col, test)\n","    \n","    train[col] = train[col].replace(mapping).astype(int)\n","    test[col] = test[col].replace(mappingTe).astype(int)\n","\n","def quadratic_weighted_kappa(y_true, y_pred):\n","    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n","\n","def threshold_Rounder(oof_non_rounded, thresholds):\n","    return np.where(oof_non_rounded < thresholds[0], 0,\n","                    np.where(oof_non_rounded < thresholds[1], 1,\n","                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n","\n","def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n","    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n","    return -quadratic_weighted_kappa(y_true, rounded_p)\n","\n","def TrainML(model_class, test_data):\n","    X = train.drop(['sii'], axis=1)\n","    y = train['sii']\n","\n","    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n","    \n","    train_S = []\n","    test_S = []\n","    \n","    oof_non_rounded = np.zeros(len(y), dtype=float) \n","    oof_rounded = np.zeros(len(y), dtype=int) \n","    test_preds = np.zeros((len(test_data), n_splits))\n","\n","    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n","        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n","        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n","\n","        model = clone(model_class)\n","        model.fit(X_train, y_train)\n","\n","        y_train_pred = model.predict(X_train)\n","        y_val_pred = model.predict(X_val)\n","\n","        oof_non_rounded[test_idx] = y_val_pred\n","        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n","        oof_rounded[test_idx] = y_val_pred_rounded\n","\n","        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n","        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n","\n","        train_S.append(train_kappa)\n","        test_S.append(val_kappa)\n","        \n","        test_preds[:, fold] = model.predict(test_data)\n","        \n","        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n","        clear_output(wait=True)\n","\n","    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n","    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n","\n","    KappaOPtimizer = minimize(evaluate_predictions,\n","                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n","                              method='Nelder-Mead')\n","    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n","    \n","    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n","    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n","\n","    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n","\n","    tpm = test_preds.mean(axis=1)\n","    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n","    \n","    submission = pd.DataFrame({\n","        'id': sample['id'],\n","        'sii': tpTuned\n","    })\n","\n","    return submission\n","\n","# Model parameters for LightGBM\n","Params = {\n","    'learning_rate': 0.046,\n","    'max_depth': 12,\n","    'num_leaves': 478,\n","    'min_data_in_leaf': 13,\n","    'feature_fraction': 0.893,\n","    'bagging_fraction': 0.784,\n","    'bagging_freq': 4,\n","    'lambda_l1': 10,  # Increased from 6.59\n","    'lambda_l2': 0.01  # Increased from 2.68e-06\n","}\n","\n","\n","# XGBoost parameters\n","XGB_Params = {\n","    'learning_rate': 0.05,\n","    'max_depth': 6,\n","    'n_estimators': 200,\n","    'subsample': 0.8,\n","    'colsample_bytree': 0.8,\n","    'reg_alpha': 1,  # Increased from 0.1\n","    'reg_lambda': 5,  # Increased from 1\n","    'random_state': SEED\n","}\n","\n","\n","CatBoost_Params = {\n","    'learning_rate': 0.05,\n","    'depth': 6,\n","    'iterations': 200,\n","    'random_seed': SEED,\n","    'cat_features': cat_c,\n","    'verbose': 0,\n","    'l2_leaf_reg': 10  # Increase this value\n","}\n","\n","# Create model instances\n","Light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)\n","XGB_Model = XGBRegressor(**XGB_Params)\n","CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n","\n","# Combine models using Voting Regressor\n","voting_model = VotingRegressor(estimators=[\n","    ('lightgbm', Light),\n","    ('xgboost', XGB_Model),\n","    ('catboost', CatBoost_Model)\n","])\n","\n","# Train the ensemble model\n","Submission2 = TrainML(voting_model, test)\n","\n","# Save submission\n","#Submission2.to_csv('submission.csv', index=False)\n","Submission2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:18:25.18058Z","iopub.status.busy":"2024-10-20T04:18:25.180146Z","iopub.status.idle":"2024-10-20T04:21:24.26648Z","shell.execute_reply":"2024-10-20T04:21:24.265352Z","shell.execute_reply.started":"2024-10-20T04:18:25.180525Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n","test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n","sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n","\n","featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n","                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n","                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n","                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n","                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n","                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n","                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n","                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n","                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n","                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n","                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n","                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n","                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n","                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n","                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n","                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n","                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n","                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n","\n","cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n","          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n","          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n","\n","train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n","test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n","\n","time_series_cols = train_ts.columns.tolist()\n","time_series_cols.remove(\"id\")\n","\n","train = pd.merge(train, train_ts, how=\"left\", on='id')\n","test = pd.merge(test, test_ts, how=\"left\", on='id')\n","\n","train = train.drop('id', axis=1)\n","test = test.drop('id', axis=1)\n","\n","featuresCols += time_series_cols\n","\n","train = train[featuresCols]\n","train = train.dropna(subset='sii')\n","\n","def update(df):\n","    global cat_c\n","    for c in cat_c: \n","        df[c] = df[c].fillna('Missing')\n","        df[c] = df[c].astype('category')\n","    return df\n","\n","train = update(train)\n","test = update(test)\n","\n","def create_mapping(column, dataset):\n","    unique_values = dataset[column].unique()\n","    return {value: idx for idx, value in enumerate(unique_values)}\n","\n","for col in cat_c:\n","    mapping = create_mapping(col, train)\n","    mappingTe = create_mapping(col, test)\n","    \n","    train[col] = train[col].replace(mapping).astype(int)\n","    test[col] = test[col].replace(mappingTe).astype(int)\n","\n","def quadratic_weighted_kappa(y_true, y_pred):\n","    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n","\n","def threshold_Rounder(oof_non_rounded, thresholds):\n","    return np.where(oof_non_rounded < thresholds[0], 0,\n","                    np.where(oof_non_rounded < thresholds[1], 1,\n","                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n","\n","def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n","    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n","    return -quadratic_weighted_kappa(y_true, rounded_p)\n","\n","def TrainML(model_class, test_data):\n","    X = train.drop(['sii'], axis=1)\n","    y = train['sii']\n","\n","    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n","    \n","    train_S = []\n","    test_S = []\n","    \n","    oof_non_rounded = np.zeros(len(y), dtype=float) \n","    oof_rounded = np.zeros(len(y), dtype=int) \n","    test_preds = np.zeros((len(test_data), n_splits))\n","\n","    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n","        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n","        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n","\n","        model = clone(model_class)\n","        model.fit(X_train, y_train)\n","\n","        y_train_pred = model.predict(X_train)\n","        y_val_pred = model.predict(X_val)\n","\n","        oof_non_rounded[test_idx] = y_val_pred\n","        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n","        oof_rounded[test_idx] = y_val_pred_rounded\n","\n","        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n","        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n","\n","        train_S.append(train_kappa)\n","        test_S.append(val_kappa)\n","        \n","        test_preds[:, fold] = model.predict(test_data)\n","        \n","        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n","        clear_output(wait=True)\n","\n","    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n","    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n","\n","    KappaOPtimizer = minimize(evaluate_predictions,\n","                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n","                              method='Nelder-Mead')\n","    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n","    \n","    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n","    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n","\n","    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n","\n","    tpm = test_preds.mean(axis=1)\n","    tp_rounded = threshold_Rounder(tpm, KappaOPtimizer.x)\n","\n","    return tp_rounded\n","\n","imputer = SimpleImputer(strategy='median')\n","\n","ensemble = VotingRegressor(estimators=[\n","    ('lgb', Pipeline(steps=[('imputer', imputer), ('regressor', LGBMRegressor(random_state=SEED))])),\n","    ('xgb', Pipeline(steps=[('imputer', imputer), ('regressor', XGBRegressor(random_state=SEED))])),\n","    ('cat', Pipeline(steps=[('imputer', imputer), ('regressor', CatBoostRegressor(random_state=SEED, silent=True))])),\n","    ('rf', Pipeline(steps=[('imputer', imputer), ('regressor', RandomForestRegressor(random_state=SEED))])),\n","    ('gb', Pipeline(steps=[('imputer', imputer), ('regressor', GradientBoostingRegressor(random_state=SEED))]))\n","])\n","\n","Submission3 = TrainML(ensemble, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:21:24.26819Z","iopub.status.busy":"2024-10-20T04:21:24.26786Z","iopub.status.idle":"2024-10-20T04:21:24.281624Z","shell.execute_reply":"2024-10-20T04:21:24.280338Z","shell.execute_reply.started":"2024-10-20T04:21:24.268153Z"},"trusted":true},"outputs":[],"source":["Submission3 = pd.DataFrame({\n","    'id': sample['id'],\n","    'sii': Submission3\n","})\n","\n","Submission3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:21:24.283679Z","iopub.status.busy":"2024-10-20T04:21:24.283253Z","iopub.status.idle":"2024-10-20T04:21:24.307013Z","shell.execute_reply":"2024-10-20T04:21:24.305885Z","shell.execute_reply.started":"2024-10-20T04:21:24.28364Z"},"trusted":true},"outputs":[],"source":["sub1 = Submission1\n","sub2 = Submission2\n","sub3 = Submission3\n","\n","sub1 = sub1.sort_values(by='id').reset_index(drop=True)\n","sub2 = sub2.sort_values(by='id').reset_index(drop=True)\n","sub3 = sub3.sort_values(by='id').reset_index(drop=True)\n","\n","combined = pd.DataFrame({\n","    'id': sub1['id'],\n","    'sii_1': sub1['sii'],\n","    'sii_2': sub2['sii'],\n","    'sii_3': sub3['sii']\n","})\n","\n","def majority_vote(row):\n","    return row.mode()[0]\n","\n","combined['final_sii'] = combined[['sii_1', 'sii_2', 'sii_3']].apply(majority_vote, axis=1)\n","\n","final_submission = combined[['id', 'final_sii']].rename(columns={'final_sii': 'sii'})\n","\n","final_submission.to_csv('submission.csv', index=False)\n","\n","print(\"Majority voting completed and saved to 'Final_Submission.csv'\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T04:21:24.309578Z","iopub.status.busy":"2024-10-20T04:21:24.308765Z","iopub.status.idle":"2024-10-20T04:21:24.325904Z","shell.execute_reply":"2024-10-20T04:21:24.32484Z","shell.execute_reply.started":"2024-10-20T04:21:24.309533Z"},"trusted":true},"outputs":[],"source":["final_submission"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9643020,"sourceId":81933,"sourceType":"competition"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":4}
